# TRAX_Translation_model
Use Encoder Decoder architecture with LSTM for English->German translation network

This Colab notebook is adapted from DeepLearning. ai / Coursera assignment [week 1 Course "Natural Language Processing with Attention Models"](https://www.coursera.org/learn/attention-models-in-nlp/home/welcome) from [Natural Language Processing Specialization](https://www.coursera.org/specializations/natural-language-processing).


# sample output

![image](https://user-images.githubusercontent.com/68251051/113909228-bb3c8300-97d7-11eb-8f88-4a6f70996cfd.png)

![image](https://user-images.githubusercontent.com/68251051/113909106-9a742d80-97d7-11eb-9277-7fcd02259d1f.png)

![image](https://user-images.githubusercontent.com/68251051/113909513-0bb3e080-97d8-11eb-8783-e70eef8d42ec.png)
